---
title: "Basics of {scanBit}"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basics of scanBit}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```

```{r libraries}
library(Seurat)
library(scanBit)
library(tidyverse)
```

## Using SNPs to define tumor clusters

### Prep the input data
```{r read_data, eval=FALSE}
# This is a Seurat object with two patient osteosarcoma mets from one patient
two_sobj <- qs::qread("/home/gdrobertslab/mvc002/analyses/roberts/dev/testSnps/output/patient_met_1/two_sobj.qs")

# Do cell type annotation so I can use macrophages and monocytes as known normal cells
# The idea is that Osteosarcoma cells are unlikely to be mistakenly annotated as macrophages or monocytes
hpca <- celldex::HumanPrimaryCellAtlasData()
imm_cells <- celldex::MonacoImmuneData()
blueprint <- celldex::BlueprintEncodeData()

cell_assign <-
    SingleR::SingleR(as.SingleCellExperiment(two_sobj),
                     ref = list(hpca,
                                imm_cells,
                                blueprint),
                     labels = list(hpca$label.main,
                                   imm_cells$label.main,
                                   blueprint$label.main))

two_sobj$cell_type <-
    cell_assign$labels

two_sobj$cell_score <-
    cell_assign$scores %>%
    apply(MARGIN = 1, function(x) max(x, na.rm = TRUE))
```

### Prepare input for scanBit
This table has three columns, `cell_barcode`, `bam_file`, and `cell_group`.

The `cell_barcode` column should contain the cell barcodes from the Seurat object. It is critical that the cell barcodes match the barcodes that will be found in the bam file. This means that if you appended/prepended sample labels to the barcodes in your Seurat object, you need to strip those off.

The `bam_file` column should contain the absolute path to the BAM file for each cell.

The `cell_group` column should contain the group that each cell belongs to (e.g., cluster or cell type). This will be used as labels in the tree image as well as the groups in the output file, so make it something meaningful.
```{r eval=FALSE}
cell_barcode_table <-
    two_sobj@meta.data %>%
    select(used_clusters) %>%
    dplyr::rename(cell_group = used_clusters) %>%
    rownames_to_column("cell_barcode") %>%
    as_tibble() %>%
    mutate(bam_file = paste0("/home/gdrobertslab/lab/Counts/",
                             str_remove(cell_barcode, "_.*"),
                             "/outs/possorted_genome_bam.bam"),
           cell_barcode = str_remove(cell_barcode, ".+_"))
```

### Run scanBit
This R command creates and runs batch jobs as part of the analysis. This is done either using a job scheduler such as slurm or SGE, or using bash shell scripts. If you want to look at these scripts, they are saved in the temporary folder (temp_folder argument). If submitting to slurm or SGE, the logs are saved there as well.

The tricky bit about running this is going to be making sure that your options for other_job_heading_options and other_batch_options are correct for your system if you are using a job scheduler on a HPC.

For other_job_header_options, this is a vector of options as strings that will be passed to the job header. This is either sbatch, qsub header elements. The code will automatically prepend either #SBATCH or #$ to the argument as appropriate.

For slurm, the code automatically adds the following header elements:

--output
--error
--job-name
--nodes
--ntasks
--cpus-per-task
--mem
--wait

If you need additional options in your job header, add them to the other_job_header_options vector.

If you are in a HPC environment and you need to specify other options for a batch job that are outside of the job header, you can add them to the other_batch_options list. This is typically used for loading modules or changing how conda works, but you can put anything that is required in this vector. These commands will be run at the top of the batch job.

If you want to test everything out, try running get_snp_tree with temp_dir set to an easy to access directory and change the submit argument to FALSE. This will generate the batch job scripts, but not submit them. Then you can look at the scripts to see if they look correct. You can also run the scripts manually to see if they work to check what options you may need to add.

### The ploidy argument
This takes either:
- A character string that will be passed to bcftools call. See bcftools call --ploidy ?. Options are
    - "GRCh37" is hg19
    - "GRCh38" is hg38
    - "X" is something I don't think anyone will use
    - "Y" also don't think anyone will ever use
    - "1" if everything is haploid
    - "2" if everything is diploid (all chromosomes, so no sex chroms and MT)
- "mm10"
    - this tells bcftools to use the ploidy file included with the package
- "mm10_hg19" or "mm10_hg38"
    This is mostly for use in our lab as it points to included ploidy files for our custom mixed species references
- The path to a custom ploidy file
    - See https://samtools.github.io/bcftools/bcftools.html#call for how to construct this


```{r eval=FALSE}
start_time <- Sys.time()

snp_tree <-
    get_snp_tree(
        cellid_bam_table = cell_barcode_table,
        temp_dir = "output/temp",
        ploidy = "GRCh37",
        output_dir = "output",
        output_base_name = "test_two_sobj",
        ref_fasta = "/home/gdrobertslab/lab/GenRef/10x-human/fasta/genome.fa",
        min_depth = c(5, 10, 20),
        job_base = "two_sobj",
        min_snvs_per_cluster = 500,
        max_prop_missing_at_site = 0.9,
        cleanup = FALSE,
        other_job_header_options = c(
            "--time=8:00:00",
            "--mail-type=ALL",
            "--mail-user=fake_email@not_a_real_domain.org",
            "--partition=himem,general"
        ),
        other_batch_options = c( # Just here as examples of things you might put
            "ml purge",
            "ml miniforge3",
            'eval "$(conda shell.bash hook)"',
            "echo Doing stuff!"
        ),
        submit = FALSE
    )

end_time <- Sys.time()
total_time <- end_time - start_time
total_time
```


## Using SGE as a job scheduler
For SGE, the code automatically adds the following header elements:

!!!
figure this out
!!!

If you're using sge, you also need to specify the `--sge_q` and `--sge_pe` options. The `--sge_q` option is the queue you want to use, and the `--sge_pe` option is the parallel environment you want to use. This is the value you would put where the word "threaded" is in the example below.

`#$ -pe thread 30`

So in in this example, you would add --sge_pe = "thread".

```{r sge}
snp_tree <-
    get_snp_tree(
        cellid_bam_table = cell_barcode_table,
        temp_dir = "output/temp",
        ploidy = "GRCh37",
        output_dir = "output",
        output_base_name = "test_two_sobj",
        ref_fasta = "/home/gdrobertslab/lab/GenRef/10x-human/fasta/genome.fa",
        min_depth = c(5, 10, 20),
        job_base = "two_sobj",
        min_snvs_per_cluster = 250,
        max_prop_missing_at_site = 0.75,
        cleanup = FALSE,
        other_job_header_options = c(
            "-l h_rt=08:00:00",
            "-m b,e",
            "-M fake_email@not_a_real_domain.org"
        ),
        other_batch_options = c( # Just here as examples of things you might put
            "ml purge",
            "ml miniforge3",
            'eval "$(conda shell.bash hook)"',
            "echo Doing stuff!"
        ),
        sge_q = "all.q",
        sge_parallel_environment = "thread",
        job_scheduler = "sge",
        submit = FALSE # This is just here so I can test things
    )
```

## Adding the results back into your Seurat object and plotting them
```{r plotting, eval = FALSE}
# Pngs of trees and text output are in the "output/" directory

# Add snv groups to the Seurat object
two_sobj <-
    add_snv_group_to_sobj(
        two_sobj,
        snv_group_file = "output/test_two_sobj_5_groups.txt",
        new_columns = c("snv_group_5", "snv_top_lvl_group_5"),
        cell_group = "used_clusters"
    ) %>%
    add_snv_group_to_sobj(
        snv_group_file = "output/test_two_sobj_10_groups.txt",
        new_columns = c("snv_group_10", "snv_top_lvl_group_10"),
        cell_group = "used_clusters"
    ) %>%
    add_snv_group_to_sobj(
        snv_group_file = "output/test_two_sobj_20_groups.txt",
        new_columns = c("snv_group_20", "snv_top_lvl_group_20"),
        cell_group = "used_clusters"
    )

DimPlot(
    two_sobj,
    group.by = c("snv_group_5", "snv_group_10", "snv_group_20", "cell_type"),
    label = TRUE,
    repel = TRUE,
    ncol = 2
) +
    NoLegend()

control_celltypes <- c("Monocytes", "Macrophages", "NK cells", "NK_cell")

# Figure out which clusters are more than 50% control celltypes
normal_clusters <-
    match_celltype_clusters(sobject = two_sobj,
                            normal_celltypes = control_celltypes,
                            cluster_col = "used_clusters",
                            celltype_col = "cell_type")

two_sobj <-
    label_tumor_cells(
        two_sobj,
        cell_group = "used_clusters",
        snv_group_col = "snv_group_20",
        normal_clusters = normal_clusters,
        tumor_call_column = "snv_tumor_call_20"
    )

DimPlot(
    two_sobj,
    group.by = c("snv_group_20", "snv_tumor_call_20", "cell_type"),
    label = TRUE,
    repel = TRUE,
    ncol = 2
) +
    NoLegend()
```
